# Review of Causal Discovery and Inference (2024–2026)

## **1\. Introduction: The Renaissance of Mechanism**

The scientific and technological landscape of the mid-2020s is defined by a decisive shift from correlational observation to causal understanding. For decades, the dominance of "big data" prioritized predictive accuracy over explanatory depth, driven by the unreasonable effectiveness of statistical learning in high-dimensional spaces. However, the period between 2024 and early 2026 has witnessed a "structural turn"—a widespread recognition that purely associative models, no matter how large, are fundamentally brittle in the face of distribution shifts, interventions, and counterfactual reasoning. This report synthesizes a comprehensive body of pre-print literature and technical reports from this period, organizing approximately 100 distinct research contributions into a unified narrative of causal discovery and inference.

The scope of this renaissance is not limited to a single discipline. In **Artificial Intelligence**, the focus has moved from scaling parameters to embedding causal priors, driven by the necessity to mitigate hallucinations and ensure fairness in high-stakes deployment. In **Fundamental Physics**, the application of rigorous causal boundaries is resolving paradoxes that have plagued quantum mechanics and general relativity for half a century, suggesting that the preservation of information is a consequence of causal unitarity. In **Biology and Neuroscience**, the abstract graphs of systems biology are being replaced by mechanistic models that can predict the outcomes of precise genetic perturbations, such as those introduced by CRISPR technologies. Finally, in **Socio-Economic and Industrial Systems**, causal inference is evolving from an academic exercise into a robust engineering discipline capable of auditing algorithmic bias, evaluating complex policy interventions, and diagnosing root causes in distributed manufacturing networks.

This report is structured to provide an exhaustive, expert-level analysis of these developments. It avoids the repetition of similar findings by integrating them into thematic clusters, using relational statements to highlight how distinct papers reinforce, contradict, or extend one another. The analysis delves into the methodological intricacies of the proposed algorithms—from the "hybrid" search strategies in causal discovery to the "lattice expansion" estimators in complexity science—offering a detailed map of the current frontier of causal knowledge.

## ---

**2\. The Algorithmic Foundation: Causal Discovery and Large Language Models**

The integration of Causal Discovery (CD) with the generative capabilities of Large Language Models (LLMs) represents the most dynamic intersection in modern computer science. The literature from 2024–2026 indicates a departure from viewing these as separate domains; instead, researchers are treating LLMs as repositories of "world knowledge" that can serve as structural priors for causal search, while simultaneously using causal formalisms to ground the reasoning of otherwise hallucination-prone models.

### **2.1 Integrating Semantic Priors into Structural Search**

Traditional causal discovery algorithms, such as the PC algorithm or Greedy Equivalence Search, operate on the assumption that variables are anonymous labels (e.g., $X\_1, X\_2$). This ignores the immense semantic richness contained in variable names and metadata. Recent advancements have focused on bridging this gap by using LLMs to guide the search process, thereby reducing the super-exponential complexity associated with discovering Directed Acyclic Graphs (DAGs).

#### **2.1.1 Hybrid Discovery Frameworks**

A significant advancement in this domain is the proposal of hybrid frameworks that merge statistical independence testing with semantic reasoning. CD identifies causal relationships among system entities, a task critical in domains like epidemiology and economics.1 However, traditional algorithms struggle with computational complexity and the integration of expert knowledge. To address this, researchers have proposed hybrid LLM-based frameworks that extend Breadth-First Search (BFS) strategies with active learning and dynamic scoring. In these systems, variable pairs are not tested randomly; rather, they are prioritized for LLM-based querying using a composite score derived from mutual information, partial correlation, and the LLM's own confidence in a causal link.2

This method has proven particularly effective in uncovering "fairness-critical paths"—causal chains that transmit bias. For instance, in benchmarks derived from the UCI Adult dataset, this hybrid approach successfully recovered pathways such as $sex \\rightarrow education \\rightarrow income$ even under conditions of injected noise and label corruption.2 This validates the hypothesis that LLMs, when constrained by statistical data, can identify mechanisms that pure data-driven methods might miss due to low statistical power or confounding.

#### **2.1.2 Scalability via Hierarchical Clustering**

While hybrid methods improve accuracy, they often face scalability bottlenecks when applied to high-dimensional datasets. Addressing this, Sokolov et al. (2024) developed a scalable solution utilizing hierarchical clustering based on semantic similarity. The innovation lies in the "divide-and-conquer" approach: the algorithm first analyzes connections *within* semantically clustered variables (which are likely to be causally related) before determining *inter-cluster* causality. This reduces the search space significantly, making causal discovery feasible for large-scale financial and biological datasets.3

This hierarchical approach contrasts with, yet complements, the "fine-tuning" strategies seen in other works. While Sokolov et al. focus on the search algorithm, other groups focus on refining the model itself. For example, fine-tuning LLMs on datasets like *CORR2CAUSE*—a benchmark specifically designed to distinguish causation from correlation—has been shown to empower models with explicit cause-and-effect knowledge.4 This suggests a future where "Causal LLMs" are pre-trained not just on text, but on structural equation models.

### **2.2 Benchmarking Causal Reasoning and Hallucination Mitigation**

The potential of LLMs is tempered by their tendency to "hallucinate"—to confidently assert false causal relationships. The pre-print literature 2024–2026 is rich with efforts to quantify and mitigate this phenomenon through rigorous benchmarking and novel decoding strategies.

#### **2.2.1 The "Causal Parrot" Phenomenon**

A critical skepticism permeates the literature, best summarized by the description of LLMs as "causal parrots." Recent research highlights that while models can recite causal facts (e.g., "smoking causes cancer"), they often fail to apply this knowledge in counterfactual reasoning or novel scenarios.5 This limitation renders them vulnerable to demographic biases and social stereotypes, as they rely on probabilistic modeling of linguistic patterns rather than an understanding of the underlying data-generating process.

To distinguish genuine reasoning from rote memorization, researchers have introduced rigorous benchmarks. *CausalProbe 2024*, for example, consists of datasets (CausalProbe-E, \-H, \-M) that include "made-up" fake cause-effect pairs (CausalProbe-H). This forces the model to reason about the structure provided in the prompt rather than relying on training data, exposing the fragility of current architectures when facing counterfactual disturbance terms.3 Similarly, the *CORR2CAUSE* dataset serves as a strict evaluator of an LLM's ability to discern causation from correlation, a distinction often blurred in natural language training corpora.4

#### **2.2.2 Algorithmic Mitigation Strategies**

Beyond benchmarking, active mitigation strategies are being developed. One promising direction is "systematic verification," which cross-references model outputs against established causal graphs to flag hallucinations.3 In the realm of video understanding—where temporal causality is paramount—researchers have proposed *Self-Diagnostic Contrastive Decoding (SEASON)*. This training-free method dynamically diagnoses the hallucination tendency of each generated token. If a token conflicts with the temporal or spatial logic of the video, the algorithm applies adaptive contrastive decoding to suppress it.7

This approach is paralleled by work in Multimodal LLMs (MLLMs), where "Causal-Driven Projectors" are introduced to the visual pathway. These projectors disentangle object representations to prevent the model from conflating distinct visual entities, effectively "intervening" on the internal representation to ensure it aligns with the causal structure of the scene.8 Such methods represent a move toward "white-box" reliability, where the internal mechanism of the model is forced to respect causal constraints.

### **2.3 Causal Representation Learning (CRL)**

While causal discovery identifies links between observed variables, Causal Representation Learning (CRL) addresses a deeper problem: discovering the high-level causal variables themselves from low-level data (e.g., pixels or sensor readings).

#### **2.3.1 Disentanglement and Identifiability**

The core challenge in CRL is that observed concepts are often "entangled." For instance, a video of a swinging pendulum contains pixel-level data that mixes the concepts of "light position," "pendulum angle," and "shadow length." Existing generative models struggle because they model the joint distribution without separating the "root factors"—the independent sources that drive the system.9

Recent theoretical work has made strides in establishing conditions for identifiability—the guarantee that the learned representations correspond to the true latent factors. Zhang et al. (2024) demonstrated that "structural sparsity" among the latent sources can enable identifiability even without an explicit causal graph. Building on this, subsequent pre-prints in 2025 propose using observed sources as "auxiliary variables." By exploiting the known causal structure of these auxiliaries, the model can recover the unknown latent sources, effectively combining the strengths of causal modeling with the flexibility of deep learning.10

#### **2.3.2 Applications in Video Anomaly Detection**

The practical utility of CRL is evident in video surveillance. Standard unsupervised anomaly detection often fails because it flags *any* statistical deviation (e.g., a change in lighting) as an anomaly. The *Causal Representation Consistency Learning (CRCL)* framework addresses this by distinguishing between "normality-endogenous" representations (causal factors of normal behavior) and "scene-dependent" biases. By employing "scene-debiasing learning," CRCL allows the model to generalize the prototype of a normal event across different environments, flagging only genuine behavioral anomalies like fighting or burglary.11

This is complemented by pipeline approaches using open-vocabulary detectors like *YOLO-World* combined with causal spatio-temporal modeling. By filtering out background noise (causal irrelevancies) and focusing on human-centric foregrounds, these systems achieve high accuracy on benchmarks like UCF-Crime, demonstrating that causal attention is key to robustness in real-world surveillance.13

## ---

**3\. Fundamental Physics: The Causal Fabric of Spacetime and Quantum Mechanics**

The application of causal reasoning has extended into the deepest questions of fundamental physics. The literature from 2024–2026 indicates that resolving the conflicts between General Relativity and Quantum Mechanics requires a rigorous re-examination of causal structures, particularly regarding information preservation and thermodynamic bounds.

### **3.1 The Black Hole Information Paradox: A Causal Resolution**

For fifty years, the "Black Hole Information Paradox" has stood as a monument to the conflict between the unitary evolution of quantum mechanics (which preserves information) and the semi-classical description of black holes (which suggests information is lost in evaporation). A series of groundbreaking pre-prints in 2025 propose a resolution based on the overlooked causal mechanism of *stimulated emission*.

#### **3.1.1 The Stimulated Emission Mechanism**

Hawking's original calculation of black hole radiation focused on *spontaneous emission*. However, Einstein’s coefficients dictate that in any thermal system, spontaneous emission must be accompanied by stimulated emission. New theoretical work argues that infalling matter acts as an incoming state that *stimulates* the emission of radiation at the horizon. This process generates "approximate clones" of the infalling information, encoded in the outgoing radiation.14

This mechanism has profound implications. By including the stimulated terms, researchers have recalculated the *Holevo capacity* of the black hole channel and found it to be strictly positive. This implies that the black hole acts as an information-preserving mirror rather than a shredder. The "cloning" at the horizon is not perfect (which would violate the No-Cloning Theorem) but is approximate, protected by the noise of spontaneous Hawking radiation, thus satisfying quantum constraints.15

#### **3.1.2 Removal of the Hidden Region**

The most radical consequence of this causal mechanism is the potential redundancy of the black hole's interior. 't Hooft (2025) proposes that the mechanism of stimulated emission effectively removes the "hidden region" from the thermodynamic description. Information deposited at the future event horizon is transported to the past event horizon via antipodal identification, determining the emission of particles. This enforces a rigorous form of boundary unitarity, suggesting that the event horizon is a causal boundary where information is reflected rather than lost.14 This aligns with "Nonviolent Unitarization" models which postulate minimal new physics at the horizon to preserve locality.16

### **3.2 Quantum Thermodynamics and Causal Bounds**

Causal reasoning is also reshaping our understanding of energy at the quantum scale, particularly in the design of "Quantum Batteries"—devices that store energy in quantum states.

#### **3.2.1 The Entanglement-Charging Advantage**

A major theoretical advance in 2025 is the derivation of a universal bound linking the charging speed of a quantum battery to its internal causal structure—specifically, its multipartite entanglement. The "Genuine Quantum Charging Advantage" is defined as the ratio between the charging rate of an entangled system and the maximum possible rate of a non-entangled (parallel) system.17

The findings suggest that to saturate the Quantum Speed Limit (QSL)—the theoretical maximum speed of evolution—the system *must* generate global multipartite entanglement. This establishes a causal necessity: entanglement is not just a byproduct but a required resource for super-extensive power scaling. Specifically, charging Hamiltonians with long-range interactions have been shown to exhibit super-linear scaling in power, confirming that the causal topology of the interaction network dictates thermodynamic performance.18

### **3.3 Time Loops and Retrocausality**

The study of Closed Timelike Curves (CTCs)—or time machines—has moved from science fiction to rigorous mathematical analysis, focusing on how causal loops can exist without logical paradoxes.

#### **3.3.1 Consistent Quantum Loops**

Recent work extends the theory of quantum time loops using "Noncommutative Möbius Transformations." Unlike previous scalar models, this framework handles multi-dimensional Hilbert spaces, resembling feedback control theory. The key insight is that physical laws might enforce a "fine-tuning" that allows only self-consistent loops. In this view, the "Grandfather Paradox" is impossible not because time travel is forbidden, but because the only dynamically allowed trajectories are those where the past is not changed in a contradictory way.20

#### **3.3.2 Retrocausality without Signaling**

Parallel research explores "backward-in-time conditional probabilities" as a way to explain Bell correlations (entanglement) without non-locality. These models posit that future measurement settings can influence past particle states (retrocausality). However, they impose a strict "Statistical Independence" condition: the macroscopic past is uncorrelated with the future settings. This ensures that while the micro-causal structure is retrocausal, no signal can be sent back in time, preserving the causal order required by Special Relativity while explaining the "spooky action at a distance" of quantum mechanics.21

### **3.4 Emergent Phenomena in Condensed Matter**

In condensed matter physics, causal mechanisms are being invoked to explain high-temperature superconductivity. The discovery of superconductivity in twisted bilayer $WSe\_2$ (tWSe2) has challenged conventional phonon-mediated theories. The appearance of the superconducting state adjacent to a magnetic phase suggests a "spin-fluctuation mediated" causal mechanism, similar to that seen in cuprates but in a fully tunable 2D material.22 Other theoretical proposals go further, hypothesizing that the electron itself might be a composite particle, with internal causal dynamics explaining the pairing mechanism.23

## ---

**4\. Biological Complexity: From Gene Editing to Consciousness**

In the life sciences, the "black box" approach of associating genotypes with phenotypes is being replaced by detailed causal modeling of the intervening mechanisms. This shift is driven by the need to predict the safety of gene editing and to understand the emergent properties of neural networks.

### **4.1 Causal Modeling of CRISPR and Off-Target Effects**

The therapeutic promise of CRISPR-Cas9 is limited by the risk of "off-target" edits—unintended genetic alterations that can cause oncogenic transformations. Causal inference is now central to mapping and mitigating these risks.

#### **4.1.1 Mechanisms of Off-Target Toxicity**

Pre-prints from 2025 describe *Superb-seq*, a novel technique that leverages T7 in situ transcription to causally link Cas9 editing events to downstream gene expression in single cells. This method has revealed that off-target edits are not random noise; they occur in specific "fat-hand" patterns, often in introns, and trigger widespread regulatory cascades.24 Understanding this causal graph—where an edit at locus $A$ causes dysregulation at loci $B, C, D$—is essential for the safety of gene therapies.

#### **4.1.2 Stochastic Intervention Models**

To infer these networks from high-throughput screens, researchers have developed "stochastic intervention models." Unlike the ideal "do-operator" ($do(X=x)$) which assumes a perfect intervention, these models account for the fact that a CRISPR guide RNA affects a *random subset* of targets (the "fat hand" problem). Algorithms designed under this assumption provide polylogarithmic competitive ratios for identifying the true causal parents in a gene regulatory network, robustly filtering out the noise of off-target effects.25

### **4.2 Neural Plasticity and Theories of Consciousness**

The brain is the ultimate causal engine, and understanding its function requires mapping the effective connectivity between neurons.

#### **4.2.1 Neuromorphic Causal Learning**

The mechanism of *Spike-Timing-Dependent Plasticity (STDP)*—where the causal order of spikes determines synaptic strengthening—is being integrated into artificial intelligence. The "Spiking STDP Transformer" embeds query-key correlations directly into synaptic weights using this biological learning rule. This represents a move toward "neuromorphic causal learning," where the hardware itself respects the temporal causality of the biological brain, offering extreme energy efficiency compared to standard transformers.26

#### **4.2.2 Causal Architectures of Consciousness**

Causal discovery is also being applied to the "hard problem" of consciousness. The debate between Global Neuronal Workspace Theory (GNWT) and Integrated Information Theory (IIT) hinges on the causal structure of neural processing. GNWT predicts a global broadcast (causal integration), while IIT predicts local recurrence. Recent fMRI studies use causal connectivity analysis to test these predictions, mapping how information flows during conscious vs. unconscious states (e.g., "inattentional deafness"). These studies suggest that consciousness is an emergent property of specific causal loop topologies in the fronto-parietal network.27

### **4.3 Quantifying Causal Emergence**

A profound theoretical question in biology is whether "macro" systems (like a school of fish or a neural network) have causal powers that are irreducible to their "micro" components.

#### **4.3.1 The Redundancy Problem and Lattice Expansion**

Previous metrics for "causal emergence" often failed in biological systems because they "double-counted" the information shared by redundant components (e.g., two neurons firing together). This led to the conclusion that the macro-scale was less informative than the micro-scale. New "Lattice Expansion" estimators solve this by iteratively correcting for redundancy. When applied to data on fish schooling, these estimators revealed that the flock *does* possess emergent causal properties—decisions made by the group that cannot be predicted by summing the individual fish. This mathematical formalism provides a rigorous basis for the concept of "downward causation" in biological hierarchies.29

## ---

**5\. Socio-Economic and Policy Systems: Robust Inference in the Wild**

In the domain of public policy, economics, and social science, causal inference is the primary tool for evaluating the impact of interventions in complex, uncontrolled environments. The literature from 2024–2026 highlights a push for robustness against model misspecification and the uncovering of systemic bias.

### **5.1 Algorithmic Fairness as Causal Auditing**

As algorithms assume the role of gatekeepers in hiring and lending, "fairness" has been redefined as a causal property.

#### **5.1.1 Process Fairness and Causal Graphs**

Bias is rarely explicit; it is hidden in the causal structure of the data. For example, a hiring algorithm might exclude women not by gender, but by penalizing "resume gaps," which are causally linked to maternity leave. Pre-prints from 2025 emphasize "Process Fairness"—the auditing of the causal graph used by the algorithm. Researchers are using causal discovery to map the dependencies in hiring data, identifying "fairness-critical paths" (e.g., $Gender \\rightarrow Gap \\rightarrow Score$). This allows for "path-specific" corrections that remove the discriminatory influence while preserving the utility of the variable.1

#### **5.1.2 Synthetic Benchmarking for Bias**

To validate these auditing tools, the community has generated synthetic datasets (e.g., *CausalProbe-Fairness*) with known causal structures of discrimination. These benchmarks allow researchers to "inject" bias (e.g., a direct link from Ethnicity to Zip Code) and verify if the discovery algorithm can recover it. This moves the field from anecdotal evidence of bias to rigorous, quantifiable auditing standards.2

### **5.2 Econometrics: Unifying Inference Paradigms**

The two workhorses of policy evaluation—Difference-in-Differences (DiD) and Synthetic Control (SC)—have been unified in a powerful new framework.

#### **5.2.1 The Doubly Robust Estimator**

DiD relies on the "parallel trends" assumption (that treated and untreated units would have evolved similarly). SC relies on constructing a perfect weighted match of untreated units. A new "Doubly Robust" framework integrates both: it yields a valid estimate of the Average Treatment Effect on the Treated (ATT) if *either* the parallel trends assumption holds *or* the synthetic control weights are valid. This provides a safety net for researchers working with microeconomic panel data (e.g., analyzing the effect of a state law on households), where neither assumption is perfectly guaranteed.31

#### **5.2.2 Financial Event Studies**

In finance, "Event Studies" attempt to measure the impact of a shock (like a merger or flash crash) on stock prices. Traditional methods use linear factor models (like the Fama-French model), which are often misspecified in volatile markets. New research demonstrates that this misspecification leads to biased causal estimates. The proposed remedy is the use of Synthetic Control methods to construct "replicating portfolios" that do not assume a linear factor structure. This approach has been shown to be more robust in detecting abnormal returns during market anomalies.32

### **5.3 Climate Systems: Feedback Loops and Tipping Points**

Climate science is perhaps the most critical application domain for causal inference, given the existential risk of "tipping points."

#### **5.3.1 Benchmarking Causal Methods for Climate**

The non-linear nature of the climate system makes causal discovery difficult. A comparative study of three methods—*Liang-Kleeman Information Flow (LKIF)*, *Peter-Clark Momentary Conditional Independence (PCMCI)*, and *Granger Causality for State Space Models (GCSS)*—offers clear guidance. **GCSS** is superior for large datasets with delayed effects (e.g., ocean currents), while **PCMCI** is best when expert knowledge must be integrated to constrain the search. **LKIF** is robust for weaker interactions.33

#### **5.3.2 The AMOC-Sea Ice Feedback**

Applying these methods to the interaction between the Atlantic Meridional Overturning Circulation (AMOC) and Arctic Summer Sea Ice (ASSI) has revealed a critical "stabilizing feedback loop." A weaker AMOC transports less heat north, which preserves sea ice; conversely, increased sea ice promotes convection that strengthens the AMOC. Identifying such loops is vital for Earth System Models, as they determine the resilience of the climate system against collapse.33

### **5.4 Rebound Effects and Jevons Paradox in AI**

A growing area of causal policy research concerns the environmental impact of AI itself. While AI can optimize energy efficiency, causal analysis warns of "rebound effects" (Jevons Paradox): increased efficiency lowers costs, which drives up demand, potentially leading to a net *increase* in consumption. Policy evaluation frameworks are now explicitly modeling these second-order causal effects to ensure that "Green AI" initiatives do not backfire.35

## ---

**6\. Industrial Applications: Reliability and Root Cause Analysis**

In the high-stakes world of industrial operations and software engineering, causal inference is transitioning from research to production-grade "Root Cause Analysis" (RCA).

### **6.1 Causal-Discovery-based Root-Cause Analysis (CD-RCA)**

When a complex system fails (e.g., a cloud microservice crashes or a manufacturing line produces defects), finding the cause is like finding a needle in a haystack. Traditional methods often rely on correlation (e.g., "CPU usage spiked when the error occurred"), which leads to false positives.

#### **6.1.1 Beyond Heuristics**

The **CD-RCA** framework, introduced in 2024, replaces heuristics with structural causal models. It treats the "prediction error" or "defect rate" as a node in a causal graph. By simulating counterfactuals on this graph—effectively asking "What would the error be if I intervened to fix this specific component?"—CD-RCA can identify the true culprit. In a case study of river inflow forecasting for dam operations, CD-RCA correctly identified upstream soil water accumulation as the root cause of prediction errors, a physical reality that correlation-based methods missed.37

#### **6.1.2 Scalability in Microservices**

Similar principles are applied in the *CausalTrace* and *SmartPilot* frameworks for microservices. These agents navigate the immense dependency graph of distributed applications, using neurosymbolic reasoning to trace failures across service boundaries. This represents a leap forward in "AIOps," where the system not only detects anomalies but explains their causal origin to human operators.38

### **6.2 Manufacturing and Neurosymbolic AI**

In semiconductor manufacturing, the complexity of process steps makes defect diagnosis notoriously difficult. New causal agents integrate data from heterogeneous sensors (temperature, pressure, chemical flow) to construct a causal graph of the production line. This "neurosymbolic" approach combines the pattern-matching of neural networks with the logical reasoning of causal graphs, providing interpretable diagnostics that help operators adjust recipes to prevent yield loss.38

## ---

**7\. Methodological Frontiers: Transportability and Nonlinear Identification**

Underpinning these applied successes are significant advances in the mathematical theory of causal inference.

### **7.1 Nonlinear Identification and Additive Noise**

A fundamental problem in causal discovery is distinguishing $X \\rightarrow Y$ from $Y \\rightarrow X$ when only observational data is available. **Additive Noise Models (ANMs)** ($Y \= f(X) \+ N$) allow for this identification if the noise is non-Gaussian.

#### **7.1.1 Kernel Methods and Mechanism Shifts**

Recent work has unified Kernel-based Granger Causality with Kernel Principal Component Regression (KPCR), extending identification capabilities to highly nonlinear dynamic systems.42 Furthermore, researchers are now focusing on "Mechanism Shifts." Instead of learning the entire graph, algorithms like *iSCAN* focus on identifying which specific causal mechanisms (edges) have changed between two datasets (e.g., before and after a system update). This uses the Jacobian of the score function to localize changes, offering a more efficient route to root cause analysis.43

### **7.2 Transportability and Domain Adaptation**

**Transportability** is the theory of transferring causal conclusions from a source domain (e.g., a clinical trial) to a target domain (e.g., the general population).

#### **7.2.1 Partial Transportability**

Standard transportability requires a complete causal diagram, which is rarely available. New research introduces "Partial Transportability," which provides bounds on the target quantity using only *partial* knowledge of the graph. Implemented via **Neural Causal Models**, this allows for robust generalization even when the full selection diagram is unknown.45

#### **7.2.2 Causal Fine-Tuning**

This theory is being applied to the fine-tuning of foundation models. "Causal Fine-Tuning" explicitly models the decomposition of inputs into "causal features" (invariant) and "spurious features" (domain-specific). By adjusting the model to rely only on the causal component, researchers can ensure that an AI trained on medical images from one hospital generalizes safely to another, despite differences in scanner protocols or patient demographics.46

## ---

**8\. Conclusion: The Age of Causal Integration**

The trajectory of research from 2024 to 2026 confirms that causality has transcended its origins as a subfield of statistics to become a foundational pillar of modern science and engineering. We are witnessing a phase of **algorithmic operationalization**.

In **AI**, this manifests as the integration of causal priors into LLMs, transforming them from stochastic parrots into reasoning agents. In **Physics**, it appears as the rigorous application of unitarity to resolve the information paradox. In **Biology**, it is the move from association studies to mechanistic network models. And in **Industry**, it is the deployment of causal graphs to ensure the reliability of the complex systems upon which society depends.

The overarching theme is a move toward **structural fidelity**: scientific and engineering models are no longer content to predict *what* will happen; they are now demanding to know *why*. This structural turn promises a future of AI that is fairer, safer, and more aligned with the physical and logical laws of the universe.

### **Statistical Summary of Key Developments**

| Domain | Key Innovation (2024-2026) | Primary Mechanism/Method | Impact/Application |
| :---- | :---- | :---- | :---- |
| **AI / LLMs** | **LLM-Guided Discovery** | Hybrid BFS \+ LLM Scoring; Hierarchical Clustering | Fairness auditing; Scalable discovery in high-dim data 1 |
| **Physics** | **Info. Paradox Resolution** | Stimulated Emission at Horizon; Unitarity | Recovering info from Black Holes; Removing "Hidden Region" 14 |
| **Quantum** | **Charging Advantage** | Entanglement Bounds; Long-range Interactions | Designing super-extensive Quantum Batteries 17 |
| **Biology** | **Causal Emergence** | Lattice Expansion Estimators | Quantifying macro-causation in flocking/networks 29 |
| **Climate** | **Feedback Analysis** | PCMCI / GCSS | Identifying AMOC-Sea Ice stabilizing loops 33 |
| **Industry** | **Root Cause Analysis** | CD-RCA (Counterfactual Scoring) | Diagnosing defects in manufacturing & microservices 37 |
| **Policy** | **Unified Inference** | Doubly Robust DiD-SC | Robust policy evaluation in panel data 31 |
| **Fairness** | **Process Fairness** | Path-specific Bias Analysis | Auditing hiring algorithms for proxy discrimination 30 |

#### **Works cited**

1. Fairness-Driven LLM-based Causal Discovery with Active Learning and Dynamic Scoring, accessed January 19, 2026, [https://arxiv.org/html/2503.17569v1](https://arxiv.org/html/2503.17569v1)  
2. Uncovering Bias Paths with LLM-guided Causal Discovery: An Active Learning and Dynamic Scoring Approach \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2506.12227v1](https://arxiv.org/html/2506.12227v1)  
3. Large Language Models for Causal Discovery: Current Landscape and Future Directions, accessed January 19, 2026, [https://arxiv.org/html/2402.11068v2](https://arxiv.org/html/2402.11068v2)  
4. ALCM: Autonomous LLM-Augmented Causal Discovery Framework \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2405.01744v2](https://arxiv.org/html/2405.01744v2)  
5. \[2410.15319\] Causality for Large Language Models \- arXiv, accessed January 19, 2026, [https://arxiv.org/abs/2410.15319](https://arxiv.org/abs/2410.15319)  
6. Unveiling Causal Reasoning in Large Language Models: Reality or Mirage? \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2506.21215v1](https://arxiv.org/html/2506.21215v1)  
7. \[2512.04643\] SEASON: Mitigating Temporal Hallucination in Video Large Language Models via Self-Diagnostic Contrastive Decoding \- arXiv, accessed January 19, 2026, [https://arxiv.org/abs/2512.04643](https://arxiv.org/abs/2512.04643)  
8. Causal-LLaVA: Causal Disentanglement for Mitigating Hallucination in Multimodal Large Language Models \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2505.19474v1](https://arxiv.org/html/2505.19474v1)  
9. Structural Disentanglement of Causal and Correlated Concepts \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2405.16219v2](https://arxiv.org/html/2405.16219v2)  
10. Towards Causal Representation Learning with Observable Sources as Auxiliaries \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2509.19058v1](https://arxiv.org/html/2509.19058v1)  
11. \[2503.18808\] CRCL: Causal Representation Consistency Learning for Anomaly Detection in Surveillance Videos \- arXiv, accessed January 19, 2026, [https://arxiv.org/abs/2503.18808](https://arxiv.org/abs/2503.18808)  
12. CRCL: Causal Representation Consistency Learning for Anomaly Detection in Surveillance Videos \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2503.18808v1](https://arxiv.org/html/2503.18808v1)  
13. Human-Centric Anomaly Detection in Surveillance Videos Using YOLO-World and Spatio-Temporal Deep Learning \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2510.22056v1](https://arxiv.org/html/2510.22056v1)  
14. \[2410.16891\] Alternative theory for the quantum black hole and the temperature of its quantum radiation \- arXiv, accessed January 19, 2026, [https://arxiv.org/abs/2410.16891](https://arxiv.org/abs/2410.16891)  
15. Paradox No More: How Stimulated Emission of Radiation Preserves ..., accessed January 19, 2026, [https://arxiv.org/abs/2502.05642](https://arxiv.org/abs/2502.05642)  
16. arXiv:2412.18650v2 \[hep-th\] 24 Feb 2025, accessed January 19, 2026, [https://arxiv.org/pdf/2412.18650](https://arxiv.org/pdf/2412.18650)  
17. Quantum Charging Advantage from Multipartite Entanglement, accessed January 19, 2026, [https://arxiv.org/abs/2503.02667](https://arxiv.org/abs/2503.02667)  
18. arXiv:2412.00921v2 \[quant-ph\] 24 Apr 2025, accessed January 19, 2026, [https://arxiv.org/pdf/2412.00921](https://arxiv.org/pdf/2412.00921)  
19. \[2412.05537\] Enhancing the Charging Performance of Many-Body Quantum Batteries through Landau-Zener Driving \- arXiv, accessed January 19, 2026, [https://arxiv.org/abs/2412.05537](https://arxiv.org/abs/2412.05537)  
20. \[2411.08543\] Quantum Time Travel Revisited: Noncommutative Möbius Transformations and Time Loops \- arXiv, accessed January 19, 2026, [https://arxiv.org/abs/2411.08543](https://arxiv.org/abs/2411.08543)  
21. arXiv:2501.11064v3 \[quant-ph\] 20 May 2025, accessed January 19, 2026, [https://arxiv.org/pdf/2501.11064](https://arxiv.org/pdf/2501.11064)  
22. \[2406.03418\] Superconductivity in twisted bilayer WSe$\_2$ \- arXiv, accessed January 19, 2026, [https://arxiv.org/abs/2406.03418](https://arxiv.org/abs/2406.03418)  
23. \[2309.05403\] A New Physical Model of Pairing Mechanism in Superconductors: Could the Electron itself be treated as a Composite Particle to Achieve Room Temperature Superconductor? \- arXiv, accessed January 19, 2026, [https://arxiv.org/abs/2309.05403](https://arxiv.org/abs/2309.05403)  
24. Joint single-cell profiling of CRISPR-Cas9 edits and transcriptomes reveals widespread off-target events and \- bioRxiv, accessed January 19, 2026, [https://www.biorxiv.org/content/10.1101/2025.02.07.636966v1.full.pdf](https://www.biorxiv.org/content/10.1101/2025.02.07.636966v1.full.pdf)  
25. \[2402.08229\] Causal Discovery under Off-Target Interventions \- arXiv, accessed January 19, 2026, [https://arxiv.org/abs/2402.08229](https://arxiv.org/abs/2402.08229)  
26. Attention via Synaptic Plasticity is All You Need: A Biologically Inspired Spiking Neuromorphic Transformer \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2511.14691v1](https://arxiv.org/html/2511.14691v1)  
27. Neural correlates of consciousness in an auditory no-report fMRI study \- bioRxiv, accessed January 19, 2026, [https://www.biorxiv.org/content/biorxiv/early/2025/05/21/2025.05.16.654468.full.pdf](https://www.biorxiv.org/content/biorxiv/early/2025/05/21/2025.05.16.654468.full.pdf)  
28. Whole-brain causal discovery using fMRI \- PMC \- PubMed Central, accessed January 19, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11949584/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11949584/)  
29. Improved estimators of causal emergence for large systems \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2601.00013](https://arxiv.org/html/2601.00013)  
30. Fairness and Bias in Algorithmic Hiring \- Semantic Scholar, accessed January 19, 2026, [https://www.semanticscholar.org/paper/Fairness-and-Bias-in-Algorithmic-Hiring-Fabris-Baranowska/4fb2223814a300631932a719ed731437d398d261](https://www.semanticscholar.org/paper/Fairness-and-Bias-in-Algorithmic-Hiring-Fabris-Baranowska/4fb2223814a300631932a719ed731437d398d261)  
31. Difference-in-Differences Meets Synthetic Control: Doubly Robust Identification and EstimationAuthors are listed in alphabetical order; all contributed equally to this work. \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2503.11375v1](https://arxiv.org/html/2503.11375v1)  
32. arxiv.org, accessed January 19, 2026, [https://arxiv.org/abs/2511.15123](https://arxiv.org/abs/2511.15123)  
33. Quantitative Comparison of Causal Inference Methods for Climate Tipping Points, accessed January 19, 2026, [https://egusphere.copernicus.org/preprints/2025/egusphere-2025-6258/](https://egusphere.copernicus.org/preprints/2025/egusphere-2025-6258/)  
34. Quantitative Comparison of Causal Inference Methods ... \- EGUsphere, accessed January 19, 2026, [https://egusphere.copernicus.org/preprints/2025/egusphere-2025-6258/egusphere-2025-6258.pdf](https://egusphere.copernicus.org/preprints/2025/egusphere-2025-6258/egusphere-2025-6258.pdf)  
35. From Efficiency Gains to Rebound Effects: The Problem of Jevons' Paradox in AI's Polarized Environmental Debate \- arXiv, accessed January 19, 2026, [https://arxiv.org/pdf/2501.16548](https://arxiv.org/pdf/2501.16548)  
36. From Efficiency Gains to Rebound Effects: The Problem of Jevons' Paradox in AI's Polarized Environmental Debate \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2501.16548v2](https://arxiv.org/html/2501.16548v2)  
37. Causal-discovery-based root-cause analysis and its ... \- arXiv, accessed January 19, 2026, [https://arxiv.org/abs/2411.06990](https://arxiv.org/abs/2411.06990)  
38. CausalTrace: A Neurosymbolic Causal Analysis Agent for Smart Manufacturing \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2510.12033v1](https://arxiv.org/html/2510.12033v1)  
39. \[2408.13729\] Root Cause Analysis for Microservice System based on Causal Inference: How Far Are We? \- arXiv, accessed January 19, 2026, [https://arxiv.org/abs/2408.13729](https://arxiv.org/abs/2408.13729)  
40. \[2502.18240\] Causal AI-based Root Cause Identification: Research to Practice at Scale, accessed January 19, 2026, [https://arxiv.org/abs/2502.18240](https://arxiv.org/abs/2502.18240)  
41. Wafer Defect Root Cause Analysis with Partial Trajectory Regression DM: Big Data Management and Machine Learning \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2507.20357v1](https://arxiv.org/html/2507.20357v1)  
42. Constraint- and Score-Based Nonlinear Granger Causality ... \- arXiv, accessed January 19, 2026, [https://arxiv.org/abs/2601.09579](https://arxiv.org/abs/2601.09579)  
43. iSCAN: Identifying Causal Mechanism Shifts among Nonlinear Additive Noise Models | OpenReview, accessed January 19, 2026, [https://openreview.net/forum?id=GEtXhqKW6X¬eId=s8goLI1kGw](https://openreview.net/forum?id=GEtXhqKW6X&noteId=s8goLI1kGw)  
44. Identifying biological perturbation targets through causal differential networks \- arXiv, accessed January 19, 2026, [https://arxiv.org/html/2410.03380v4](https://arxiv.org/html/2410.03380v4)  
45. \[2503.23605\] Partial Transportability for Domain Generalization \- arXiv, accessed January 19, 2026, [https://arxiv.org/abs/2503.23605](https://arxiv.org/abs/2503.23605)  
46. \[2410.14375\] Attuned to Change: Causal Fine-Tuning under Latent-Confounded Shifts, accessed January 19, 2026, [https://arxiv.org/abs/2410.14375](https://arxiv.org/abs/2410.14375)